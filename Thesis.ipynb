{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thesis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C--6qLM63-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bltk\n",
        "!pip install nltk\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUCGU4E0gwTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import bltk\n",
        "import nltk\n",
        "import numpy as np\n",
        "import regex as re\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from bltk.langtools import Tokenizer, remove_stopwords\n",
        "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.linear_model import LinearRegression, SGDClassifier, LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qwz8QPfx2pA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_excel('/content/drive/My Drive/Colab Notebooks/thesis_dataset.xlsx')\n",
        " \n",
        "data = df\n",
        "X = data['Review']\n",
        "X.dropna(inplace=True)\n",
        "print(X)\n",
        " \n",
        "y = data['Label']\n",
        "y.dropna(inplace=True)\n",
        "len(y)\n",
        " \n",
        "lebel=[]\n",
        "for item in y:\n",
        "    lebel.append(int(item))\n",
        "#print(lebel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCfRxyNE2ghj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pattern=r\"([!@#$%^&*(),.?-_+\\`·:={}|<>A-Za-z0-90.0।Ⓒ©®»/০-৯'])\"\n",
        "def preprocess(string):\n",
        "  result=re.sub(pattern,\" \",str(string))\n",
        "  vlue=word_tokenize(result)\n",
        "  #stopword_removed=remove_stopwords(vlue,level='hard')\n",
        "  Single_list=list(dict.fromkeys(vlue))\n",
        "  return Single_list\n",
        "new=[]\n",
        "for lines in X:\n",
        "  result = preprocess(lines)\n",
        "  new.append(result)\n",
        "print(new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTReyQcBZvDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "negations = [\"না\", \"নি\", \"নাই\", \"নাহ\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFwB9PN08AR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiments(text):\n",
        " \n",
        "  sentiwords = pd.read_excel('/content/drive/My Drive/Thesis_Final_Works/sentiword (1).xlsx')\n",
        "  positive_words = sentiwords['Positive'].tolist()\n",
        "  negative_words = sentiwords['Negative'].tolist()\n",
        "  positive_count = 0\n",
        "  negetive_count = 0\n",
        "  neutral_count = 0\n",
        "  contradictory = 0\n",
        " \n",
        "  length = len(text)\n",
        " \n",
        "  for first_word in text:\n",
        "    if first_word in positive_words:\n",
        "      positive_count += 1\n",
        "    elif first_word in negative_words:\n",
        "      negetive_count += 1\n",
        "    else:\n",
        "      neutral_count += 1\n",
        " \n",
        "  # for j in range(0, length-2):\n",
        "  #   if text[j] in contra_postive and text[j+1] in negative_words:\n",
        "  #     #if text[j+1] in negations:\n",
        "  #       #contradictory +=1\n",
        "  #     if text[j+2] in negations:\n",
        "  #       contradictory +=1\n",
        "  for j in range(0, length-2):\n",
        "    if text[j] in negative_words:\n",
        "      if text[j+1] in negations:\n",
        "        contradictory +=1\n",
        "      elif text[j+2] in negations:\n",
        "        contradictory +=1\n",
        "  \n",
        " \n",
        "  if contradictory > 0:\n",
        "    return 3 \n",
        "  elif negetive_count > 0:\n",
        "    if positive_count == 0:\n",
        "      return 1\n",
        "    elif negetive_count >= positive_count:\n",
        "      return 2\n",
        "    else:\n",
        "      return 3\n",
        "  elif positive_count > 0:\n",
        "    if negetive_count == 0:\n",
        "      return 4\n",
        "    elif positive_count  >  negetive_count:\n",
        "      return 3\n",
        "    else:\n",
        "      return 2\n",
        "  elif (positive_count > 0 ) and (negetive_count > 0) and (positive_count == negetive_count):\n",
        "    return 2\n",
        "  else:\n",
        "    return 0\n",
        " \n",
        "output_label = []\n",
        "#print(new)\n",
        "for sen in new: \n",
        "  ouput = sentiments(sen) \n",
        "  output_label.append(ouput)\n",
        "print(output_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLhsULvnl-oM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(output_label)\n",
        "print(lebel)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD3PlKl7oXdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_one=np.array(lebel)\n",
        "X = np.reshape(X_one, (-1, 1))\n",
        " \n",
        "y_one=np.array(output_label)\n",
        "y1=np.reshape(y_one, (-1, 1))\n",
        "X_train,X_test,y_train,y_test= train_test_split(X,y1,test_size=0.3, random_state=43)\n",
        "print(len(X_train))\n",
        "print(len(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_9GRu1io14-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        " \n",
        "X_train=X_train.reshape(-1,1)\n",
        " \n",
        "text_clf=Pipeline([('Classifier', LinearSVC())])\n",
        "text_clf.fit(X_train,y_train)\n",
        " \n",
        "text_clf1=Pipeline([('Classifier', RandomForestClassifier())])\n",
        "text_clf1.fit(X_train,y_train)\n",
        " \n",
        "prediction= text_clf.predict(X_test)\n",
        "prediction1 = text_clf1.predict(X_test)\n",
        "print(metrics.confusion_matrix(y_test,prediction))\n",
        "print(classification_report(y_test,prediction))\n",
        "print(metrics.accuracy_score(y_test,prediction))\n",
        " \n",
        "print(f\"\\n\\n{metrics.confusion_matrix(y_test,prediction1)}\")\n",
        "print(classification_report(y_test,prediction1))\n",
        "print(f\"\\n\\n\\nAccuracy : {metrics.accuracy_score(y_test,prediction1):2.2%}\\n\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2PI-drA0mPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "text_clf1.fit(X_train, y_train)\n",
        "y_predicted = text_clf1.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_predicted)\n",
        "sns.heatmap(cm, annot = True, fmt= 'd')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSbpdEe6Fc41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CM=confusion_matrix(y_test,prediction1)\n",
        "print(CM)\n",
        "print(classification_report(y_test,prediction1))\n",
        "#print(classification_report(y_test,prediction))\n",
        "count=0\n",
        "TP=0\n",
        "FN=0\n",
        "FP=0\n",
        "TN=0\n",
        "Sum=0\n",
        "I=0\n",
        "for i in range(0,len(CM)):\n",
        "  for j in range(0,len(CM)):\n",
        "    Sum=Sum+CM[i][j]\n",
        " \n",
        " \n",
        "for i in range(0,len(CM)):\n",
        "  TP=0\n",
        "  FN=0\n",
        "  FP=0\n",
        "  TN=0\n",
        "  for j in range(0,len(CM)):\n",
        "    if i==j:\n",
        "      TP=CM[i][j]\n",
        "    else:\n",
        "      FN=FN+CM[i][j]\n",
        "      FP=FP+CM[j][i]\n",
        "  TN=Sum-TP-FP-FN\n",
        "  accuracy = (TP+TN) / (TP+FN+FP+TN)\n",
        "  precision = TP / (TP+FP)\n",
        "  recall = TP / (TP + FN)\n",
        " \n",
        "  f1_score = (2*precision*recall) / (precision+recall)\n",
        "  specificity = TN / (TN+FP)\n",
        "  sensitivity = recall\n",
        "  print(f\"\\n\\nTP:{TP} FN:{FN} FP:{FP} TN:{TN} SUM:{Sum}\")\n",
        "  print('Precision: {:2.2%}'.format(precision))\n",
        "  print('Recall: {:2.2%}'.format(recall))\n",
        "  print('F1 Score: {:2.2%}'.format(f1_score))\n",
        "  print('Specificity: {:2.2%}'.format(specificity))\n",
        "  print('Sensitivity: {:2.2%}'.format(sensitivity))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ynfm4-smvRSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_text=input()\n",
        "prediction_text_clen=preprocess(prediction_text)\n",
        "prediction_emotion=np.reshape(sentiments(prediction_text_clen),(1,-1))\n",
        "prediction_output=text_clf1.predict(prediction_emotion)\n",
        "if prediction_output == 4:\n",
        "  print(\"\\nREVIEW: Very Positive\")\n",
        "elif prediction_output == 3:\n",
        "  print(\"\\nREVIEW: Positive\")\n",
        "elif prediction_output == 1:\n",
        "  print(\"\\nREVIEW: Very Negative\")\n",
        "elif prediction_output == 2:\n",
        "  print(\"\\nREVIEW: Negative\")\n",
        "else:\n",
        "  print(\"\\nREVIEW: Neutral\")\n",
        "  print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAMQH3Wc0jN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e_37_tV17VO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}